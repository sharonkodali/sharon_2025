{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "toc: true\n",
    "title: Hacks Tools and equipment play \n",
    "description: Sprint 1\n",
    "authors: Sharon Kodali\n",
    "categories: [AP CSA]\n",
    "courses: { csa: {week: 3} }\n",
    "type: ccc\n",
    "permalink: /toolhacks\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wikipedia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwikipedia\u001b[39;00m  \u001b[39m# import wikipedia library to generate random titles and access page contents\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39memoji\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m  \u001b[39m# for word cleaning\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wikipedia'"
     ]
    }
   ],
   "source": [
    "import wikipediaapi  # import wikipedia-api library to access page contents\n",
    "import emoji\n",
    "import re  # for word cleaning\n",
    "import random\n",
    "\n",
    "# Create Wikipedia object for fetching pages\n",
    "wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "# Random list of article titles (manually created since random() isn't supported)\n",
    "sample_titles = [\"Python (programming language)\", \"Quantum mechanics\", \"Climate change\", \"Machine learning\", \"Internet\"]\n",
    "\n",
    "ARTICLES = 5\n",
    "total_unique_words = 0\n",
    "emojis = [\":zero:\", \":one:\", \":two:\", \":three:\", \":four:\", \":five:\", \":six:\", \":seven:\", \":eight:\", \":nine:\"]\n",
    "\n",
    "mean_unique_word_count = \"\"\n",
    "\n",
    "# Function to count unique words in a text\n",
    "def count_unique_words(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "    unique_words = [word for word, count in word_freq.items() if count == 1]\n",
    "    return len(unique_words)\n",
    "\n",
    "# Iterate through sample titles to fetch content and calculate unique words\n",
    "for i, title in enumerate(sample_titles[:ARTICLES]):\n",
    "    page = wiki.page(title)\n",
    "    if page.exists():\n",
    "        unique_word_count = count_unique_words(page.text)\n",
    "        print(f\"{i + 1}. {title}: {unique_word_count} unique words\")\n",
    "        total_unique_words += unique_word_count\n",
    "    else:\n",
    "        print(f\"Page '{title}' does not exist.\")\n",
    "\n",
    "# Calculate average unique word count\n",
    "average_unique_words = total_unique_words / ARTICLES\n",
    "\n",
    "# Convert the digits of the average unique word count into emojis\n",
    "for num in str(round(average_unique_words)):\n",
    "    mean_unique_word_count += emoji.emojize(emojis[int(num)], language='alias')\n",
    "\n",
    "# Print final average unique word count\n",
    "print(f\"\\nAverage unique word count of the {ARTICLES} random articles: {mean_unique_word_count}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
